# Research & Investigation: Timeline Integration & Event Replay System

**Feature**: 009-timeline-playback
**Date**: 2026-01-09
**Status**: Complete

---

## 1. IndexedDB Schema Design

### Decision

Use a single IndexedDB database "visual-reactivity-db" with one object store "recordings" using auto-incrementing keys.

**Schema**:
```typescript
Database: "visual-reactivity-db"
Version: 1

Object Store: "recordings"
  - keyPath: "id" (auto-increment)
  - Indexes:
    - "name" (unique): For duplicate name validation
    - "dateCreated": For sorting by date

Record Structure:
{
  id: number;              // Auto-generated by IndexedDB
  name: string;            // User-provided name (validated, unique)
  dateCreated: number;     // Timestamp (milliseconds since epoch)
  eventCount: number;      // Cached count for list display
  duration: number;        // Total duration (ms from first to last event)
  version: string;         // Format version (e.g., "1.0.0")
  events: ReactivityEvent[]; // Full event array (serialized)
}
```

### Rationale

- **Single object store**: Recordings are simple entities with no relationships
- **Auto-increment keys**: Simpler than UUID, sufficient for local storage
- **Unique name index**: Enforces name uniqueness constraint from spec (Q4 clarification)
- **dateCreated index**: Enables efficient sorting for "recent recordings" list
- **Denormalized events array**: Avoids complex joins, acceptable for read-heavy workload
- **Cached metadata**: eventCount/duration for list display without deserializing events

### Alternatives Considered

**Alternative A: Separate object store for events**
- Rejected: Adds complexity (relationships, joins), no performance benefit for our use case
- Recordings are always loaded in full for replay

**Alternative B: Use compound key (name + timestamp)**
- Rejected: Auto-increment is simpler, name uniqueness handled by index

### Implementation Pattern

```typescript
// Open database
const db = await indexedDB.open("visual-reactivity-db", 1);
db.onupgradeneeded = (event) => {
  const db = event.target.result;
  const store = db.createObjectStore("recordings", { keyPath: "id", autoIncrement: true });
  store.createIndex("name", "name", { unique: true });
  store.createIndex("dateCreated", "dateCreated", { unique: false });
};

// Save recording (with unique name check)
const tx = db.transaction("recordings", "readwrite");
const store = tx.objectStore("recordings");
const request = store.add(recording); // Throws if name exists (unique index)

// Load all recordings (sorted by date)
const index = store.index("dateCreated");
const recordings = await index.getAll(IDBKeyRange.lowerBound(0), "prev"); // Descending
```

---

## 2. Historical State Reconstruction Algorithm

### Decision

Use **incremental event replay with memoized snapshots** (hybrid approach).

**Algorithm**:
1. Maintain in-memory snapshot cache (Map<timestamp, GraphSnapshot>)
2. On first reconstruction at time T:
   - Replay events from 0 to T, build snapshot
   - Cache snapshot at T
3. On subsequent reconstructions at time T+N:
   - Find nearest cached snapshot before T+N
   - Replay only events from snapshot to T+N
   - Cache new snapshot at T+N
4. Limit cache size to 100 snapshots (LRU eviction)

**Snapshot Structure**:
```typescript
interface GraphSnapshot {
  timestamp: number;
  activeNodes: Map<string, { node: ReactiveNode; value: any }>;
  edges: ReactiveEdge[];
  disposedNodeIds: Set<string>;
}
```

### Rationale

- **Incremental replay**: Avoids full replay from 0 on every step (meets <100ms target)
- **Snapshot caching**: Amortizes replay cost across multiple reconstructions
- **LRU eviction**: Prevents unbounded memory growth during long replay sessions
- **Balance**: Fast enough for stepping (typically 1 snapshot apart), efficient for scrubbing (finds nearest snapshot)

### Performance Characteristics

| Operation | Without Cache | With Cache (Hit) | With Cache (Miss, 100 events apart) |
|-----------|---------------|------------------|--------------------------------------|
| First reconstruction | O(N) events | O(N) events | O(N) events |
| Step forward | O(N) events | O(1) events | O(100) events |
| Scrub to nearby time | O(N) events | O(k) events | O(k) events, k = events since nearest snapshot |

**Expected**: Step-through is O(1) with cache, meets <100ms target easily

### Alternatives Considered

**Alternative A: Full replay from 0 every time**
- Rejected: O(N) on every step, fails <100ms target for large recordings
- Would require 1M events/second to meet target for 100k event recording

**Alternative B: Event sourcing with full snapshot every 1000 events**
- Rejected: Fixed intervals waste memory (snapshots at unused timestamps)
- Dynamic caching (our approach) adapts to user navigation patterns

**Alternative C: Persistent snapshots (save to IndexedDB)**
- Rejected: Over-engineering for v1, adds I/O overhead
- In-memory cache sufficient for single session

### Implementation Notes

```typescript
class HistoricalStateReconstructor {
  private snapshots = new LRUCache<number, GraphSnapshot>(100);
  
  async reconstructAt(timestamp: number): Promise<GraphSnapshot> {
    // Find nearest snapshot before timestamp
    const nearest = this.snapshots.findNearest(timestamp);
    const startTime = nearest?.timestamp ?? 0;
    const startState = nearest?.snapshot ?? this.emptySnapshot();
    
    // Replay events from nearest snapshot to target
    const events = tracker.getEventsBetween(startTime, timestamp);
    const snapshot = this.applyEvents(startState, events);
    
    // Cache and return
    this.snapshots.set(timestamp, snapshot);
    return snapshot;
  }
}
```

---

## 3. Animation Interruption Pattern

### Decision

Use D3's `transition.interrupt()` API to cancel ongoing animations before starting new ones.

**Pattern**:
```typescript
function animateGraphTransition(graph: GraphData, duration: number) {
  // Interrupt any ongoing transitions on the same selection
  d3.select(svgElement)
    .selectAll('.node')
    .interrupt('graph-transition'); // Named transition for selective interruption
  
  // Start new transition
  const nodes = d3.select(svgElement)
    .selectAll('.node')
    .data(graph.nodes)
    .transition('graph-transition')
    .duration(duration)
    .attr('cx', d => d.x)
    .attr('cy', d => d.y)
    .attr('opacity', d => d.visible ? 1 : 0);
  
  return nodes;
}

// In step handler
function handleStep() {
  // Cancel current animation (if any)
  animateGraphTransition(newGraphState, 300);
}
```

### Rationale

- **Named transitions**: Allow selective interruption without affecting other animations
- **D3 built-in**: `interrupt()` is designed for this use case
- **Immediate effect**: Transition stops immediately, new one starts at current position
- **Smooth result**: No visual glitches, cursor jumps feel responsive

### Alternatives Considered

**Alternative A: Track animation state manually, check before starting**
- Rejected: More complex, requires manual state management
- D3's interrupt() handles this internally

**Alternative B: Use requestAnimationFrame cancellation**
- Rejected: D3 transitions don't expose RAF handles directly
- Would require reimplementing D3 transition system

### SolidJS Integration

```typescript
// In component
const [animationId, setAnimationId] = createSignal<number>(0);

createEffect(() => {
  const cursorTime = replayStore.cursorTime();
  if (cursorTime !== null) {
    // Increment animation ID to cancel previous
    setAnimationId(id => id + 1);
    const currentId = animationId() + 1;
    
    // Start animation
    const graphState = historicalState.reconstructAt(cursorTime);
    animateGraphTransition(graphState, 300);
  }
});
```

**Note**: SolidJS effects already batch, so rapid arrow key presses will naturally debounce to last keypress

---

## 4. Recording Serialization Format

### Decision

Use versioned JSON with explicit schema version field at root level.

**Format Version 1.0.0**:
```json
{
  "formatVersion": "1.0.0",
  "metadata": {
    "name": "Recording Name",
    "dateCreated": 1704844800000,
    "eventCount": 1234,
    "duration": 5000,
    "appVersion": "0.9.0",
    "nodeTypes": ["signal", "memo", "effect"]
  },
  "events": [
    {
      "type": "signal-write",
      "nodeId": "signal-1",
      "timestamp": 1000,
      "value": 42,
      "previousValue": 0
    },
    {
      "type": "computation-execute-start",
      "nodeId": "memo-1",
      "timestamp": 1001
    }
  ],
  "exportOptions": {
    "valueInclusion": "truncated",
    "truncationLimit": 10240
  }
}
```

### Rationale

- **formatVersion at root**: Immediately visible for compatibility check
- **Semantic versioning**: Follows semver for breaking changes (major), new fields (minor), fixes (patch)
- **Metadata separate from events**: Easy to display without parsing events
- **exportOptions preserved**: Documents how export was created (for diagnostics)
- **Flat event array**: Simple, efficient for JSON.parse/stringify

### Versioning Strategy

| Change Type | Version Bump | Compatibility |
|-------------|-------------|---------------|
| Add optional metadata field | MINOR | Backward compatible (old readers ignore) |
| Add new event type | MINOR | Backward compatible (old readers ignore) |
| Remove required field | MAJOR | Breaking (old readers fail) |
| Change event structure | MAJOR | Breaking (old readers fail) |

### Import Validation

```typescript
function validateRecording(json: unknown): Recording | Error {
  // Check format version
  const parsed = JSON.parse(json);
  const version = parsed.formatVersion;
  
  if (!version) {
    return new Error("Missing formatVersion field");
  }
  
  const [major] = version.split('.').map(Number);
  const [expectedMajor] = CURRENT_VERSION.split('.').map(Number);
  
  if (major !== expectedMajor) {
    console.warn(`Version mismatch: got ${version}, expected ${CURRENT_VERSION}`);
    // Attempt import anyway, may fail on structure mismatch
  }
  
  // Validate schema...
  return parsed as Recording;
}
```

### Alternatives Considered

**Alternative A: No versioning**
- Rejected: Makes future format changes impossible without breaking imports

**Alternative B: Version in metadata object**
- Rejected: Harder to access, requires parsing metadata first

**Alternative C: Use protocol buffers or MessagePack**
- Rejected: JSON is human-readable, easier to debug, sufficient for our use case
- Export is infrequent operation, JSON size acceptable

---

## 5. Large Recording Optimization

### Decision

**Three-tier strategy**:

1. **Tier 1 (< 10,000 events)**: No optimization, render all events
2. **Tier 2 (10,000 - 50,000 events)**: Event aggregation for display, full data for replay
3. **Tier 3 (> 50,000 events)**: Sampling + virtualization + lazy loading

**Tier 2 Implementation** (10k-50k events):
```typescript
// Aggregate events for timeline display
function aggregateEvents(events: Event[], pixelWidth: number): AggregatedEvent[] {
  const eventsPerPixel = events.length / pixelWidth;
  
  if (eventsPerPixel < 2) {
    return events; // No aggregation needed
  }
  
  // Group events by pixel bucket
  const buckets = groupByPixel(events, pixelWidth);
  
  return buckets.map(bucket => ({
    timestamp: bucket[0].timestamp,
    count: bucket.length,
    types: [...new Set(bucket.map(e => e.type))],
    representative: bucket[0], // Show first event in bucket
  }));
}
```

**Tier 3 Implementation** (>50k events):
```typescript
// Sample events for initial load
function sampleEvents(events: Event[], targetCount: number): Event[] {
  const step = Math.ceil(events.length / targetCount);
  return events.filter((_, i) => i % step === 0);
}

// Lazy load full data when user zooms in
function loadEventRange(startTime: number, endTime: number): Promise<Event[]> {
  // Query full events only for visible time range
  return indexedDB.getEventsBetween(startTime, endTime);
}
```

### Rationale

- **Progressive degradation**: User experience remains good at any scale
- **Tier 1 (default)**: Most users, no overhead
- **Tier 2 (medium)**: Aggregation preserves visual density without memory bloat
- **Tier 3 (large)**: Sampling + lazy loading prevents initial freeze
- **Replay unaffected**: Historical state reconstruction uses full data (indexed access)

### Performance Targets

| Metric | Tier 1 (<10k) | Tier 2 (10k-50k) | Tier 3 (>50k) |
|--------|---------------|------------------|---------------|
| Initial render | <500ms | <1s | <2s |
| Scrubbing FPS | 60fps | 60fps | 60fps |
| Memory usage | ~5MB | ~15MB | ~30MB (sampled) |
| Replay latency | <50ms | <100ms | <200ms |

**All tiers meet spec requirements** (SC-009: <5s load for 10k+ events)

### Alternatives Considered

**Alternative A: Always aggregate (even <10k events)**
- Rejected: Adds complexity for majority use case
- Most recordings will be <10k events

**Alternative B: Virtual scrolling only (no aggregation)**
- Rejected: Timeline is horizontal, virtual scrolling less effective
- Aggregation reduces render count more efficiently

**Alternative C: Store pre-aggregated data in IndexedDB**
- Rejected: Premature optimization, increases storage cost
- Aggregation is fast enough to do on-demand

### Implementation Notes

```typescript
// Auto-detect tier
function selectOptimizationTier(eventCount: number): 'none' | 'aggregate' | 'sample' {
  if (eventCount < 10_000) return 'none';
  if (eventCount < 50_000) return 'aggregate';
  return 'sample';
}

// Apply optimization
const tier = selectOptimizationTier(recording.events.length);
const displayEvents = tier === 'none' ? events :
                      tier === 'aggregate' ? aggregateEvents(events, width) :
                      sampleEvents(events, 5000); // Sample to 5k for display
```

---

## Summary of Decisions

| Research Area | Decision | Key Benefit |
|---------------|----------|-------------|
| IndexedDB Schema | Single object store, auto-increment keys, unique name index | Simple, enforces constraints |
| State Reconstruction | Incremental replay with memoized snapshots (LRU cache) | <100ms latency, O(1) stepping |
| Animation Interruption | D3 transition.interrupt() with named transitions | Immediate cancellation, built-in |
| Serialization Format | Versioned JSON (semver), formatVersion at root | Future-proof, human-readable |
| Large Recording Optimization | Three-tier strategy (render all / aggregate / sample) | Scales to 100k+ events |

**All decisions align with spec requirements and clarifications (Q1-Q5)**

---

**Research Complete**: 2026-01-09
**Next Phase**: Phase 1 (Design & Contracts)
